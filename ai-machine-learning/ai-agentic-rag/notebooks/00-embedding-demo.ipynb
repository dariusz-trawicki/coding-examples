{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d6304e6",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab875570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 1.000 | How to enable cruise control in a car?\n",
      "1: 0.522 | How to turn on the speed keeping system?\n",
      "2: 0.055 | What is the capital of Poland?\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "texts = [\n",
    "    \"How to enable cruise control in a car?\",\n",
    "    \"How to turn on the speed keeping system?\",\n",
    "    \"What is the capital of Poland?\"\n",
    "]\n",
    "\n",
    "# Load the embedding model (text → vector representation)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert sentences into numerical vectors (embeddings)\n",
    "emb = model.encode(texts)\n",
    "\n",
    "# cosine_similarity() computes cosine similarity between vectors.\n",
    "# It measures how similar two vectors are in terms of their *direction*\n",
    "# (not their length).\n",
    "#\n",
    "# Returned values:\n",
    "# - close to 1.0 → very similar meaning\n",
    "# - around 0.0 → little or no semantic similarity\n",
    "# - negative values (rare for sentence embeddings) → opposite meaning\n",
    "#\n",
    "# Mathematical definition:\n",
    "# cos(φ) = A · B / (||A|| * ||B||)\n",
    "# where:\n",
    "# - A · B is the dot product of vectors A and B\n",
    "# - ||A|| and ||B|| are the vector norms (lengths)\n",
    "\n",
    "# Here we compute similarity of all sentences\n",
    "# relative to the first sentence (emb[0])\n",
    "sim = cosine_similarity([emb[0]], emb)[0]\n",
    "\n",
    "# Print similarity scores for each sentence\n",
    "for i, s in enumerate(sim):\n",
    "    print(f\"{i}: {s:.3f} | {texts[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c45ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrics dim: (3, 384)\n",
      "Number of texts: 3\n",
      "Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "# Embedding dimensions:\n",
    "print(f\"Embedding matrics dim: {emb.shape}\")\n",
    "print(f\"Number of texts: {emb.shape[0]}\")\n",
    "print(f\"Embedding dimension: {emb.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dt-rag)",
   "language": "python",
   "name": "dt-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
