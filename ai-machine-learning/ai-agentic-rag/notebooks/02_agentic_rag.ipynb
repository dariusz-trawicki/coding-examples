{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4124f622",
   "metadata": {},
   "source": [
    "### Agentic RAG With LangGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7309ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from langchain.schema import Document\n",
    "from langchain_core.documents import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733dbdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3675ecda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize models\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a3353",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7424db63",
   "metadata": {},
   "source": [
    "## State Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59befbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    question: str\n",
    "    documents: List[Document]\n",
    "    answer: str\n",
    "    needs_retrieval: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad06275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Sample Docuemnt And VectorStore\n",
    "# Sample documents for demonstration\n",
    "sample_texts = [\n",
    "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain with the ability to coordinate multiple chains across multiple steps of computation in a cyclic manner.\",\n",
    "    \"RAG (Retrieval-Augmented Generation) is a technique that combines information retrieval with text generation. It retrieves relevant documents and uses them to provide context for generating more accurate responses.\",\n",
    "    \"Vector databases store high-dimensional vectors and enable efficient similarity search. They are commonly used in RAG systems to find relevant documents based on semantic similarity.\",\n",
    "    \"Agentic systems are AI systems that can take actions, make decisions, and interact with their environment autonomously. They often use planning and reasoning capabilities.\"\n",
    "]\n",
    "\n",
    "documents=[Document(page_content=text) for text in sample_texts]\n",
    "\n",
    "##create vector store\n",
    "vectorstore = FAISS.from_documents(documents, embeddings)\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f94c2",
   "metadata": {},
   "source": [
    "### Agents function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8586493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_retrieval(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Decide if we need to retrieve documents based on the question\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    # Simple heuristic: if question contains certain keywords, retrieve\n",
    "    retrieval_keywords = [\"what\", \"how\", \"explain\", \"describe\", \"tell me\"]\n",
    "    needs_retrieval = any(keyword in question.lower() for keyword in retrieval_keywords)\n",
    "    \n",
    "    return {**state, \"needs_retrieval\": needs_retrieval}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46abbde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents based on the question\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    \n",
    "    return {**state, \"documents\": documents}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d44011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    Generate an answer using the retrieved documents or direct response\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    \n",
    "    if documents:\n",
    "        # RAG approach: use documents as context\n",
    "        context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
    "        prompt = f\"\"\"Based on the following context, answer the question:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    else:\n",
    "        # Direct response without retrieval\n",
    "        prompt = f\"Answer the following question: {question}\"\n",
    "    \n",
    "    response = llm.invoke(prompt)\n",
    "    answer = response.content\n",
    "    \n",
    "    return {**state, \"answer\": answer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2e947",
   "metadata": {},
   "source": [
    "### conditional Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retrieve(state: AgentState) -> str:\n",
    "    \"\"\"\n",
    "    Determine the next step based on retrieval decision\n",
    "    \"\"\"\n",
    "    if state[\"needs_retrieval\"]:\n",
    "        return \"retrieve\"\n",
    "    else:\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8aa18",
   "metadata": {},
   "source": [
    "### build the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea2c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the state graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"decide\", decide_retrieval)\n",
    "workflow.add_node(\"retrieve\", retrieve_documents)\n",
    "workflow.add_node(\"generate\", generate_answer)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"decide\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"decide\",\n",
    "    should_retrieve,\n",
    "    {\n",
    "        \"retrieve\": \"retrieve\",\n",
    "        \"generate\": \"generate\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(\"retrieve\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf98bef7",
   "metadata": {},
   "source": [
    "### test the Agentic System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6349f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question: str):\n",
    "    \"\"\"\n",
    "    Helper function to ask a question and get an answer\n",
    "    \"\"\"\n",
    "    initial_state = {\n",
    "        \"question\": question,\n",
    "        \"documents\": [],\n",
    "        \"answer\": \"\",\n",
    "        \"needs_retrieval\": False\n",
    "    }\n",
    "    \n",
    "    result = app.invoke(initial_state)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d321ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a question that should trigger retrieval\n",
    "question1 = \"What is LangGraph?\"\n",
    "result1 = ask_question(question1)\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with another question\n",
    "question2 = \"How does RAG work?\"\n",
    "result2 = ask_question(question2)\n",
    "\n",
    "print(f\"Question: {question2}\")\n",
    "print(f\"Retrieved documents: {len(result2['documents'])}\")\n",
    "print(f\"Answer: {result2['answer']}\")\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dt-rag)",
   "language": "python",
   "name": "dt-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
